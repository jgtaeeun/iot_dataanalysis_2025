{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "### Pytorch  Í∏∞Î∞ò Î¨ºÏ≤¥Ïù∏Ïãù Î™®Îç∏\n",
    "- CNN , RCNN(Regions with CNN)\n",
    "- https://github.com/ultralytics/ultralytics\n",
    "#### YOLOv5 Ïù¥ÏÉÅ ÏÑ§Ïπò\n",
    "```shell\n",
    "> pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### yolo  ÏÑ§Ïπò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 974.8/974.8 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/39.5 MB 76.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 63.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 8.1/39.5 MB 65.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.5/39.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.1/39.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 19.9/39.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.2/39.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 24.0/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.3/39.5 MB 50.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.2/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.9/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.5/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 50.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 43.5 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.0/162.0 kB ? eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pyyaml, opencv-python, ultralytics-thop, ultralytics\n",
      "Successfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 pyyaml-6.0.2 ultralytics-8.3.109 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ÏΩòÏÜîÏóêÏÑú ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
      "Ultralytics 8.3.109 üöÄ Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
      "image 1/1 c:\\Source\\iot_dataanalysis_2025\\day53\\bus.jpg: 640x480 4 persons, 1 bus, 71.1ms\n",
      "Speed: 2.4ms preprocess, 71.1ms inference, 138.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\predict\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 65.7MB/s]\n",
      "\n",
      "  0%|          | 0.00/134k [00:00<?, ?B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134k/134k [00:00<00:00, 8.54MB/s]\n"
     ]
    }
   ],
   "source": [
    "# yolo11n.pt - pretrained YOLO model\n",
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ÏÑ§Ï†ï Í¥ÄÎ†®\n",
    "    - C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\settings.json\n",
    "    - ÏÑ§Ï†ïÏùÑ ÌôïÏù∏ÌïòÍ±∞ÎÇò Î∞îÍæ∏Î†§Î©¥:\n",
    "        - ÏÑ§Ï†ï Î≥¥Í∏∞: yolo settings\n",
    "        - ÏÑ§Ï†ï Î≥ÄÍ≤Ω: yolo settings ÌÇ§=Í∞í\n",
    "        - Ïòà: yolo settings runs_dir=c:/your/folder\n",
    "-  Î™®Îç∏ Îã§Ïö¥Î°úÎìú :yolo11n.ptÎùºÎäî Î™®Îç∏ ÌååÏùºÏùÑ ÏûêÎèôÏúºÎ°ú Îã§Ïö¥Î°úÎìú ÌñàÏñ¥Ïöî.\n",
    "    - Ïù¥Í±¥ YOLOv8Ïùò Ï¥àÍ≤ΩÎüâ Î≤ÑÏ†Ñ (n = nano).\n",
    "- Î™®Îç∏ Ï†ïÎ≥¥\n",
    "    - YOLO11n Î™®Îç∏ÏùÄ Ï¥ù 100Í∞úÏùò Î†àÏù¥Ïñ¥, ÏïΩ 260Îßå Í∞úÏùò ÌååÎùºÎØ∏ÌÑ∞.\n",
    "    - Ï≤òÎ¶¨ ÏÜçÎèÑ: 6.5 GFLOPs Ï†ïÎèÑÎ°ú Í∞ÄÎ≥çÍ≥† Îπ†Î¶Ñ.\n",
    "    - ÏÇ¨Ïö©Ìïú GPU: RTX 4060 (8GB)\n",
    "- Ïù¥ÎØ∏ÏßÄ ÏòàÏ∏°\n",
    "    - ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄ bus.jpgÎèÑ ÏûêÎèôÏúºÎ°ú Îã§Ïö¥Î°úÎìúÌñàÍ≥†,\n",
    "    - Í≤∞Í≥º: 4Î™ÖÏùò ÏÇ¨Îûå, 1ÎåÄÏùò Î≤ÑÏä§Î•º Í∞êÏßÄ.\n",
    "    - Í≤∞Í≥º Ï†ÄÏû• ÏúÑÏπò: C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\predict\n",
    "    - <img src = '../runs\\detect\\predict/bus.jpg' width =300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ÌååÏù¥Ïç¨ÏúºÎ°ú ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Î™®Îìà Î°úÎìú\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO ÌÅ¥ÎûòÏä§Í∞Ä Îì§Ïñ¥Ïò§Îäî Î™®Îç∏Ïùò Î≤ÑÏ†ÑÏóê Îî∞Îùº ÏïåÏïÑÏÑú YOLO ÏòàÏ∏°Î™®Îç∏ Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "model = YOLO('./yolo11n.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### coco8.yaml\n",
    "- Train/val/test + Classes + ÌõàÎ†®ÎÇ¥Ïö©\n",
    "    - https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml\n",
    "- Ïù¥ÎØ∏ÏßÄÌååÏùº\n",
    "    - https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip\n",
    "- https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml ÎÇ¥Ïö©ÎåÄÎ°ú ÌõàÎ†®ÏùÑ ÏãúÌÇ® Í≤∞Í≥º ->yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=./yolo11n.pt, data=./coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\n",
      "\n",
      "Dataset 'coco8.yaml' images not found , missing path 'C:\\Source\\datasets\\coco8\\images\\val'\n",
      "Downloading https://ultralytics.com/assets/coco8.zip to 'C:\\Source\\datasets\\coco8.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433k/433k [00:00<00:00, 14.6MB/s]\n",
      "Unzipping C:\\Source\\datasets\\coco8.zip to C:\\Source\\datasets\\coco8...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 1180.40file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (0.9s), saved to \u001b[1mC:\\Source\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 17.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 3972.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Source\\datasets\\coco8\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 3998.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Source\\datasets\\coco8\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.707G      1.098       2.75      1.479         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.567       0.85      0.878      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      0.73G      1.163      2.778      1.474         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557       0.85      0.887      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.736G      1.089      2.497      1.216         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.559       0.85       0.85      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.746G      1.164      2.793      1.485         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.543       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.746G       1.21      2.467      1.617         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.548       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.779G     0.8327      1.918      1.148         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.859      0.858      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.799G      1.407      2.753      1.768         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.534      0.864      0.859      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.809G      1.241      3.857      1.692         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557      0.867      0.863      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.822G     0.9127      2.976      1.275         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.867      0.897      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      0.84G       1.08      2.198      1.296         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.533      0.867      0.895      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.854G      1.173      2.263      1.557         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.644      0.944      0.912       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.869G      1.014      2.356      1.396         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.649      0.944      0.911      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.885G      1.366      3.254      1.807         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.912      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.898G     0.8433      2.457      1.262         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.913      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.914G      1.271       3.04      1.525         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.633      0.783       0.91      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.928G      1.211       2.04      1.509         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.634      0.783       0.91       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.943G     0.8203      1.549      1.184         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.963G     0.6249      1.342     0.9999         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      0.98G     0.7282      1.613      1.054         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.988G      1.177      1.758       1.35         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.01G     0.7776      1.808      1.186         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.02G      1.074        1.7      1.246         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      1.04G     0.9644      1.743      1.406         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.05G     0.9311      1.658      1.233         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.07G     0.6523      2.014      1.068         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      1.08G     0.8513      1.312      1.179         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100       1.1G     0.9637       1.47      1.404         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.11G      0.965      1.211      1.248         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.13G     0.9284      1.656      1.281         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      1.14G      1.035      1.272      1.322         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      1.16G      1.009      1.692      1.347         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      1.17G     0.6691      1.512      1.309         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.19G      1.045      1.949      1.348         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100       1.2G      1.075      1.947      1.457         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.22G     0.9153      1.245      1.311         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.23G      1.023       1.47      1.386         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.25G     0.9758      1.044      1.337         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      1.26G     0.5493     0.8292     0.9508         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      1.28G     0.7212     0.7923      1.174         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      1.29G     0.7664      1.003      1.164         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      1.31G     0.7671      1.106      1.122         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      1.32G      0.896       1.09      1.177         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      1.34G      1.001     0.9861      1.479         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      1.35G     0.6848     0.9406      1.084         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      1.37G     0.6584      1.435       1.09         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      1.38G     0.8697      1.017      1.258         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100       1.4G     0.8764     0.7681      1.263         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      1.41G     0.7879      1.029      1.148         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      1.43G     0.9999      1.108      1.374         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      1.44G     0.6589     0.8777      1.103         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      1.46G     0.7199     0.9254      1.211         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      1.47G     0.8262      1.654       1.19         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100       1.5G     0.6383      1.049       1.08         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      1.51G     0.7169     0.9855      1.103         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      1.51G     0.6532      1.136      1.145         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      1.54G     0.6833      0.849      1.217         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      1.55G     0.7164     0.7322      1.212         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      1.56G     0.7792      1.026      1.192         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      1.59G     0.7671     0.7373      1.254         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100       1.6G     0.7434      1.025      1.287         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100       1.6G     0.6051      0.688      1.063         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      1.63G     0.7546     0.9266      1.297         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      1.64G     0.6662     0.8457      1.163         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      1.65G     0.7963     0.7768      1.086         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      1.67G     0.6187      0.695      1.042         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      1.69G     0.9413      1.951      1.333         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      1.69G     0.7584     0.9315      1.182         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      1.72G     0.6322     0.7745      1.027         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      1.73G     0.7433     0.7106       1.29         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      1.74G      1.022      1.079      1.452          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      1.76G     0.6662      0.703      1.152         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      1.78G     0.6165     0.9729      1.152         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      1.78G     0.5635     0.5976      1.116         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      1.81G      1.061       1.89      1.486         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      1.82G     0.9339     0.8899      1.234         60        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      1.83G     0.9155     0.8915      1.335         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      1.85G     0.6779     0.6292      1.043         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      1.87G     0.6606      1.006      1.126         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      1.88G     0.8996      1.456      1.344         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100       1.9G      0.621     0.6226       1.12         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      1.91G     0.7918     0.7814      1.107         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      1.92G     0.4436     0.4465     0.9404         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      1.94G     0.6752     0.7486      1.039         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 26.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      1.96G     0.8206      1.379      1.272         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      1.96G     0.6159     0.7253      1.174         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      1.99G     0.6397     0.8651      1.157         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100         2G     0.5913     0.6655      1.095         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      2.02G     0.7254     0.9907      1.119         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      2.02G     0.6493     0.7954      1.159         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      2.04G     0.8045     0.6919      1.105         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      2.06G      0.571     0.5492       1.06         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      2.08G     0.4512     0.4808     0.8512         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      2.08G     0.4633     0.4968     0.9587         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      2.11G      0.609     0.6229      1.094         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      2.12G     0.5564     0.6846      1.062         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      2.14G     0.8399     0.7876      1.226         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      2.14G      0.521      0.455     0.8951         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 23.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      2.17G     0.5424     0.6244      1.008         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      2.18G     0.5596     0.5313      1.007         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100       2.2G     0.4525       0.45     0.9363         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.852      0.463      0.525      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.635      0.783       0.91      0.647\n",
      "                person          3         10      0.616        0.7      0.654      0.325\n",
      "                   dog          1          1      0.517          1      0.995      0.796\n",
      "                 horse          1          2      0.578          1      0.995       0.65\n",
      "              elephant          1          2       0.55          1      0.828      0.323\n",
      "              umbrella          1          1      0.552          1      0.995      0.895\n",
      "          potted plant          1          1          1          0      0.995      0.895\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_results = model.train(\n",
    "    data ='./coco8.yaml' ,\n",
    "    epochs = 100,\n",
    "    imgsz =640,\n",
    "    device = 'cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ïù¥ÎØ∏ÏßÄ ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Source\\iot_dataanalysis_2025\\day53\\cat.jpg: 480x640 1 cat, 43.9ms\n",
      "Speed: 7.2ms preprocess, 43.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# yolo11n.pt  Î™®Îç∏Î°ú Ïù¥ÎØ∏ÏßÄ ÏòàÏ∏°\n",
    "result = model('./cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplot Î™®Îìà Î°úÎìú\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏòàÏ∏°Í≤∞Í≥ºÎ•º Ïù¥ÎØ∏ÏßÄ+Î∞ïÏä§Î°ú Ïù¥ÎØ∏ÏßÄ ÎßåÎì§Ïñ¥ Ï†ÄÏû•ÌïòÍ∏∞\n",
    "\n",
    "# Î™®Îç∏Ïù¥ ÏòàÏ∏°Ìïú Í∞ùÏ≤¥(Î∞îÏö¥Îî© Î∞ïÏä§ Îì±)Î•º Ïù¥ÎØ∏ÏßÄ ÏúÑÏóê Í∑∏Î†§Ï§Ä Í≤∞Í≥ºÎ•º NumPy Î∞∞Ïó¥Î°ú ÏñªÏùÑ Ïàò ÏûàÏñ¥\n",
    "img = result[0].plot()\n",
    "\n",
    "\n",
    "# imgÎäî OpenCV Ïä§ÌÉÄÏùºÏùò BGR Ìè¨Îß∑Ïù¥Ïïº (Blue-Green-Red)\n",
    "# PIL.Image.fromarray()Îäî RGB Ìè¨Îß∑ÏùÑ Í∏∞ÎåÄÌï¥\n",
    "# Í∑∏ÎûòÏÑú [..., ::-1]Î°ú Ï±ÑÎÑê ÏàúÏÑúÎ•º Îí§ÏßëÏñ¥ÏÑú RGBÎ°ú Î∞îÍæ∏Îäî Í≤ÉÏù¥Ïïº\n",
    "img_pil = Image.fromarray(img[...,::-1])\n",
    "\n",
    "\n",
    "img_pil.save('./predict_result.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OpenCV\n",
    "- Opensource Computer VisionÏùò ÏïΩÏûê . Ïã§ÏãúÍ∞Ñ Ïª¥Ìì®ÌÑ∞ÎπÑÏ†Ñ(ÏãúÍ∞ÅÏ≤òÎ¶¨) Î™©Ï†ÅÏùò ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
    "- Ïù∏ÌÖîÏóêÏÑú 2000ÎÖÑÏóê C, C++ ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú Í∞úÎ∞ú\n",
    "- ÌååÏù¥Ïç¨ÏóêÏÑú ÏÇ¨Ïö©Ìï† Ïàò ÏûàÍ≤å ÎûòÌïë\n",
    "```shell\n",
    ">pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 640, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('./predict_result.jpg')\n",
    "img2.shape     #(464, 640, 3) ->(height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏúàÎèÑÏö∞ Ï∞Ω Ïò§Ìîà\n",
    "\n",
    "cv2.imshow('predict_result', img2)\n",
    "\n",
    "# ÌÇ§Î≥¥Îìú ÏûÖÎ†•ÏùÑ Í∏∞Îã§Î¶¨Îäî Ìï®Ïàò\n",
    "# 0Ïù¥Î©¥ ‚Üí Î¨¥ÌïúÌûà Í∏∞Îã§Î¶º (ÌÇ§Î≥¥Îìú ÏïÑÎ¨¥ ÌÇ§ÎÇò ÎàÑÎ•º ÎïåÍπåÏßÄ)\n",
    "# cv2.waitKey(1000)Ï≤òÎüº Ïì∞Î©¥ ‚Üí 1000ms(1Ï¥à) ÎèôÏïà Í∏∞Îã§Î¶∞ Îí§ ÏûêÎèô Ï¢ÖÎ£å\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# mshow()Î°ú ÎùÑÏö¥ Î™®Îì† Ï∞ΩÏùÑ Îã´Ïùå\n",
    "# Ïó¨Îü¨ Ïù¥ÎØ∏ÏßÄ Ï∞ΩÏùÑ ÎùÑÏõ†ÏùÑ ÎïåÎèÑ Ï†ÑÎ∂Ä Ìïú Î≤àÏóê Îã´ÏïÑÏ§òÏöî\n",
    "# Ïïà Ïì∞Î©¥ Ï∞ΩÏù¥ Í∑∏ÎåÄÎ°ú ÎÇ®ÏïÑ ÏûàÏùÑ Ïàò ÏûàÏñ¥Ïöî (ÌäπÌûà JupyterÎÇò IDEÏóêÏÑúÎäî)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './cv2Î°úÏúàÎèÑÏö∞Ï∞ΩÏóêpredict_resultÎùÑÏö∞Í∏∞.png' width=500>\n",
    "<img src = './predict_resultÏù¥ÎØ∏ÏßÄÌÅ¨Í∏∞(ÎÜíÏù¥,ÎÑàÎπÑ).png' width=500>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 1 bottle, 1 cup, 1 bowl, 1 dining table, 1 tv, 1 mouse, 1 book, 45.9ms\n",
      "Speed: 10.5ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "#objects.jpg Ïù¥ÎØ∏ÏßÄÍ∞Ä ÎÑàÎ¨¥ Ïª§ÏÑú ÏÇ¨Ïù¥Ï¶à Ï°∞Ï†ï Î®ºÏ†Ä\n",
    "img = cv2.imread('./objects.jpg')\n",
    "resized_img = cv2.resize(img, (640,400))\n",
    "\n",
    "\n",
    "result = model(resized_img)\n",
    "plots = result[0].plot()\n",
    "\n",
    "cv2.imshow('predct_result2', plots)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './predict_result2Î•ºwindowÏ∞ΩÏóêÎùÑÏö∞Í∏∞.png' width=500>\n",
    "<img src = './predict_result2Ïù¥ÎØ∏ÏßÄÌÅ¨Í∏∞.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ÎèôÏòÅÏÉÅ ÌîåÎ†àÏù¥\n",
    "- ÎùºÏ¶àÎ≤†Î¶¨ ÏõπÏ∫† ÏÇ¨Ïö©Ï∂îÏ≤ú\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './sample01.mp4'\n",
    "output_path = './sample01_output.mp4'\n",
    "count_path = './sample01_count.mp4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÇ¨Ïö©Ìï¥ÏÑú ÎèôÏòÅÏÉÅÏùÑ Ïû¨ÏÉùÌïòÎäî Í∏∞Î≥∏Ï†ÅÏù∏ ÏΩîÎìú\n",
    "\n",
    "#cv2.VideoCaptureÎäî ÎπÑÎîîÏò§ Ï∫°Ï≤ò Í∞ùÏ≤¥Î•º ÎßåÎì§Ïñ¥Ï£ºÍ≥†, Ïù¥ Í∞ùÏ≤¥Î•º ÌÜµÌï¥ ÌîÑÎ†àÏûÑ(Ïù¥ÎØ∏ÏßÄ) Îã®ÏúÑÎ°ú ÎèôÏòÅÏÉÅÏùÑ ÏùΩÏùÑ Ïàò ÏûàÏñ¥Ïöî.\n",
    "cap = cv2.VideoCapture(video_path)  \n",
    "\n",
    "while cap.isOpened():   # ÎèôÏòÅÏÉÅ ÌååÏùºÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Ïó¥Î†∏ÎäîÏßÄ ÌôïÏù∏\n",
    "    ret, frame = cap.read()   # Ìïú ÌîÑÎ†àÏûÑÏî© ÏùΩÏäµÎãàÎã§. retÏùÄ ÏùΩÍ∏∞Ïóê ÏÑ±Í≥µÌñàÎäîÏßÄÎ•º ÎÇòÌÉÄÎÇ¥Îäî Î∂àÎ¶¨Ïñ∏ Í∞í (True ÎòêÎäî False) frameÏùÄ ÏùΩÏñ¥Ïò® Ïã§Ï†ú **Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞(ÌîÑÎ†àÏûÑ)**ÏûÖÎãàÎã§.\n",
    "    if not ret : break\n",
    "\n",
    "    cv2.imshow('Video Play', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "cap.release()  #ÎπÑÎîîÏò§ Ï∫°Ï≤ò Í∞ùÏ≤¥Î•º Ìï¥Ï†úÌï©ÎãàÎã§. (Î©îÎ™®Î¶¨ Ï†ïÎ¶¨)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO Ïã§ÏãúÍ∞Ñ ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÏãúÍ∞Ñ Î™®Îìà Î°úÎìú\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 1 clock, 22.4ms\n",
      "Speed: 3.2ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 44.3ms\n",
      "Speed: 2.2ms preprocess, 44.3ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 49.9ms\n",
      "Speed: 3.1ms preprocess, 49.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 3.6ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.2ms\n",
      "Speed: 1.2ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 1 clock, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.6ms\n",
      "Speed: 1.2ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 toilet, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 4.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 3.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 1 clock, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.2ms\n",
      "Speed: 2.4ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 7.3ms\n",
      "Speed: 2.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.8ms\n",
      "Speed: 2.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 clock, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.9ms\n",
      "Speed: 2.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 2.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 7.0ms\n",
      "Speed: 2.2ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.8ms\n",
      "Speed: 3.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 truck, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 cell phone, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suitcase, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 7.0ms\n",
      "Speed: 2.9ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 2.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2. VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0/fps\n",
    "\n",
    "# ÏòÅÏÉÅÏùò ÌîÑÎ†àÏûÑ ÎÑàÎπÑÏôÄ ÎÜíÏù¥Î•º Í∞ÄÏ†∏Ïò¥ ‚Üí Ï†ÄÏû•Ìï† ÏòÅÏÉÅÏùò ÏÇ¨Ïù¥Ï¶àÎ°ú ÏÇ¨Ïö©Îê®.\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#  ÏòÅÏÉÅ Ï†ÄÏû• Í∞ùÏ≤¥ ÏÑ§Ï†ï (VideoWriter)\n",
    "# fourcc: ÎèôÏòÅÏÉÅ ÏΩîÎç± ÏÑ§Ï†ï (Ïó¨Í∏∞ÏÑ† 'mp4v' ‚Üí mp4 ÌååÏùºÎ°ú Ï†ÄÏû• Í∞ÄÎä•)\n",
    "# out: ÌÉêÏßÄ Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† ÎπÑÎîîÏò§ ÌååÏùº ÏÉùÏÑ± (output_pathÏóê Ï†ÄÏû•Îê®)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : break\n",
    "\n",
    "    # Í∞ùÏ≤¥ ÌÉêÏßÄ\n",
    "    results = model(frame)\n",
    "    for result in results :\n",
    "        detect_frame = result.plot()\n",
    "\n",
    "    # ÌÉêÏßÄ Í≤∞Í≥ºÍ∞Ä ÌëúÏãúÎêú ÌîÑÎ†àÏûÑÏùÑ ÏÉà ÏòÅÏÉÅ ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "    out.write(detect_frame)\n",
    "\n",
    "    # detect_frame: ÌÉêÏßÄ Í≤∞Í≥º ÌëúÏãúÎêú ÏòÅÏÉÅ\n",
    "    cv2.imshow('YOLO Object Detection', detect_frame)\n",
    "    # frame: ÏõêÎ≥∏ ÏòÅÏÉÅ (ÎπÑÍµêÏö©)\n",
    "    cv2.imshow('Video Play', frame)\n",
    "\n",
    "    # ÌîÑÎ†àÏûÑ ÏÜçÎèÑ ÎßûÏ∂îÍ∏∞\n",
    "    # Ïã§Ï†ú Ï≤òÎ¶¨Ïóê Í±∏Î¶∞ ÏãúÍ∞Ñ Ï∏°Ï†ï\n",
    "    elapsed_time =time.time() -start_time  \n",
    "    # ÏòÅÏÉÅ ÏõêÎûò ÏÜçÎèÑÏôÄ ÎßûÏ∂îÍ∏∞ ÏúÑÌï¥ delay Í≥ÑÏÇ∞ (ms Îã®ÏúÑ)  + ÎÑàÎ¨¥ Îπ†Î•¥Î©¥ ÏµúÏÜå 1ms ÎåÄÍ∏∞\n",
    "    delay = max(int((frame_time-elapsed_time)*1000),1)\n",
    "   \n",
    "    # Ï¢ÖÎ£å Ï°∞Í±¥\n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q') :\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Car counting\n",
    "- ÏßÄÏ†ïÎêú ÎùºÏù∏ ÏïÑÎûòÎ°ú ÎÇ¥Î†§Ïò§Îäî ÏûêÎèôÏ∞® Í∞úÏàò Ïπ¥Ïö¥ÌåÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely==2.0.1\n",
      "  Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from shapely==2.0.1) (1.26.4)\n",
      "Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# shapely ÏÑ§Ïπò\n",
    "!pip install shapely==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lap\n",
      "  Downloading lap-0.5.12-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from lap) (1.26.4)\n",
      "Downloading lap-0.5.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#lap ÏÑ§ÏπòÏπò\n",
    "!pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'records': 5, 'show': True, 'model': 'yolo11n.pt', 'line_width': 3}\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 3.4ms preprocess, 15.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 25.2ms\n",
      "Speed: 5.7ms preprocess, 25.2ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 2 trains, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 toilet, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.0ms\n",
      "Speed: 1.1ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 13.8ms\n",
      "Speed: 1.2ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 8 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 9 cars, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.0ms\n",
      "Speed: 3.4ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.2ms\n",
      "Speed: 1.2ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.1ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) #ÎèôÏòÅÏÉÅ FPS\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "line_points = [(20,400),(1080,400)]\n",
    "\n",
    "#videowriter Í∞ùÏ≤¥ ÏÉùÏÑ±( ÎèôÏòÅÏÉÅ ÌôîÎ©¥Ïóê Í∑∏Î¶º, Í∏ÄÏûêÎ•º Í∑∏Î¶¨Í∏∞ ÏúÑÌïú Í∞ùÏ≤¥)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(count_path, fourcc, fps, (width, height))\n",
    "\n",
    "#Î¨ºÏ≤¥ Ïπ¥Ïö¥ÌÑ∞ Ï¥àÍ∏∞Ìôî\n",
    "counter = solutions.ObjectCounter(\n",
    "    show = True ,# Ï≤òÎ¶¨ÌïòÎäî ÎèôÏïà ÎîîÏä§ÌîåÎ†àÏù¥ Ïó¨Î∂Ä\n",
    "    region = line_points,\n",
    "    model = 'yolo11n.pt'    #ÏÉÅÎåÄ Í≤ΩÎ°ú (ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨)  . ÎÇ¥Î∂ÄÏ†ÅÏúºÎ°ú ./yolo11n.ptÎ°ú Ìï¥ÏÑùÌï®\n",
    "\n",
    ")\n",
    "\n",
    "# ÎßåÏïΩ ÏΩîÎìú Ïã§Ìñâ Ï§ëÏóê ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨ (cwd)Í∞Ä Î∞îÎÄåÍ±∞ÎÇò,\n",
    "# ÌòπÏùÄ Í≤ΩÎ°úÍ∞Ä Î≥µÏû°Ìïú ÏúÑÏπòÏóê ÏûàÏùÑ Í≤ΩÏö∞:\n",
    "# 'yolo11n.pt'Îäî Î™ª Ï∞æÏùÑ Ïàò ÏûàÏùå\n",
    "# './yolo11n.pt' ÎòêÎäî os.path.abspath()Î°ú Î™ÖÌôïÌïòÍ≤å Ïç®Ïïº Ïò§Î•òÎ•º ÌîºÌï† Ïàò ÏûàÏùå\n",
    "# import os\n",
    "# model_path = os.path.abspath('yolo11n.pt')\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : break      #ÏûêÎèôÏúºÎ°ú Ï∞ΩÏù¥ Îã´ÌûàÍ≤å\n",
    "\n",
    "    #Ïπ¥Ïö¥ÌåÖ Í≤∞Í≥ºÎ•º ÏõêÎ≥∏Ïóê Î∞îÎ°ú Í∑∏Î¶º\n",
    "    results = counter(frame) \n",
    "    out.write(results.plot_im)\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
