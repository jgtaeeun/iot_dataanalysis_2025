{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "### Pytorch  기반 물체인식 모델\n",
    "- CNN , RCNN(Regions with CNN)\n",
    "- https://github.com/ultralytics/ultralytics\n",
    "#### YOLOv5 이상 설치\n",
    "```shell\n",
    "> pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### yolo  설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 974.8/974.8 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/39.5 MB 76.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 63.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 8.1/39.5 MB 65.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 14.5/39.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.1/39.5 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 19.9/39.5 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.2/39.5 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 24.0/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.3/39.5 MB 50.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.2/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.9/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.5/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/39.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 50.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 43.5 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.0/162.0 kB ? eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pyyaml, opencv-python, ultralytics-thop, ultralytics\n",
      "Successfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 pyyaml-6.0.2 ultralytics-8.3.109 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 콘솔에서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
      "Ultralytics 8.3.109 🚀 Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
      "image 1/1 c:\\Source\\iot_dataanalysis_2025\\day53\\bus.jpg: 640x480 4 persons, 1 bus, 71.1ms\n",
      "Speed: 2.4ms preprocess, 71.1ms inference, 138.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\predict\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\n",
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 65.7MB/s]\n",
      "\n",
      "  0%|          | 0.00/134k [00:00<?, ?B/s]\n",
      "100%|██████████| 134k/134k [00:00<00:00, 8.54MB/s]\n"
     ]
    }
   ],
   "source": [
    "# yolo11n.pt - pretrained YOLO model\n",
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 설정 관련\n",
    "    - C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\settings.json\n",
    "    - 설정을 확인하거나 바꾸려면:\n",
    "        - 설정 보기: yolo settings\n",
    "        - 설정 변경: yolo settings 키=값\n",
    "        - 예: yolo settings runs_dir=c:/your/folder\n",
    "-  모델 다운로드 :yolo11n.pt라는 모델 파일을 자동으로 다운로드 했어요.\n",
    "    - 이건 YOLOv8의 초경량 버전 (n = nano).\n",
    "- 모델 정보\n",
    "    - YOLO11n 모델은 총 100개의 레이어, 약 260만 개의 파라미터.\n",
    "    - 처리 속도: 6.5 GFLOPs 정도로 가볍고 빠름.\n",
    "    - 사용한 GPU: RTX 4060 (8GB)\n",
    "- 이미지 예측\n",
    "    - 테스트 이미지 bus.jpg도 자동으로 다운로드했고,\n",
    "    - 결과: 4명의 사람, 1대의 버스를 감지.\n",
    "    - 결과 저장 위치: C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\predict\n",
    "    - <img src = '../runs\\detect\\predict/bus.jpg' width =300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 파이썬으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 모듈 로드\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 클래스가 들어오는 모델의 버전에 따라 알아서 YOLO 예측모델 객체 생성\n",
    "model = YOLO('./yolo11n.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### coco8.yaml\n",
    "- Train/val/test + Classes + 훈련내용\n",
    "    - https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml\n",
    "- 이미지파일\n",
    "    - https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip\n",
    "- https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco8.yaml 내용대로 훈련을 시킨 결과 ->yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=./yolo11n.pt, data=./coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\n",
      "\n",
      "Dataset 'coco8.yaml' images not found , missing path 'C:\\Source\\datasets\\coco8\\images\\val'\n",
      "Downloading https://ultralytics.com/assets/coco8.zip to 'C:\\Source\\datasets\\coco8.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433k/433k [00:00<00:00, 14.6MB/s]\n",
      "Unzipping C:\\Source\\datasets\\coco8.zip to C:\\Source\\datasets\\coco8...: 100%|██████████| 25/25 [00:00<00:00, 1180.40file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (0.9s), saved to \u001b[1mC:\\Source\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Admin\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 17.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\train... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 3972.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Source\\datasets\\coco8\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 3998.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Source\\datasets\\coco8\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.707G      1.098       2.75      1.479         21        640: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.567       0.85      0.878      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      0.73G      1.163      2.778      1.474         36        640: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557       0.85      0.887      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.736G      1.089      2.497      1.216         20        640: 100%|██████████| 1/1 [00:00<00:00, 11.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.559       0.85       0.85      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.746G      1.164      2.793      1.485         21        640: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.543       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.746G       1.21      2.467      1.617         19        640: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.548       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.779G     0.8327      1.918      1.148         22        640: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.859      0.858      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.799G      1.407      2.753      1.768         20        640: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.534      0.864      0.859      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.809G      1.241      3.857      1.692         20        640: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557      0.867      0.863      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.822G     0.9127      2.976      1.275         20        640: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.867      0.897      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      0.84G       1.08      2.198      1.296         25        640: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.533      0.867      0.895      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.854G      1.173      2.263      1.557         31        640: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.644      0.944      0.912       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.869G      1.014      2.356      1.396         31        640: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.649      0.944      0.911      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.885G      1.366      3.254      1.807         24        640: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.912      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.898G     0.8433      2.457      1.262         15        640: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.913      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.914G      1.271       3.04      1.525         38        640: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.633      0.783       0.91      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.928G      1.211       2.04      1.509         49        640: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.634      0.783       0.91       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.943G     0.8203      1.549      1.184         25        640: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.963G     0.6249      1.342     0.9999         16        640: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      0.98G     0.7282      1.613      1.054         34        640: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.988G      1.177      1.758       1.35         25        640: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      1.01G     0.7776      1.808      1.186         26        640: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      1.02G      1.074        1.7      1.246         52        640: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      1.04G     0.9644      1.743      1.406         22        640: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      1.05G     0.9311      1.658      1.233         34        640: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      1.07G     0.6523      2.014      1.068         11        640: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      1.08G     0.8513      1.312      1.179         35        640: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100       1.1G     0.9637       1.47      1.404         24        640: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      1.11G      0.965      1.211      1.248         35        640: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      1.13G     0.9284      1.656      1.281         28        640: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      1.14G      1.035      1.272      1.322         29        640: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      1.16G      1.009      1.692      1.347         25        640: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      1.17G     0.6691      1.512      1.309         20        640: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      1.19G      1.045      1.949      1.348         31        640: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100       1.2G      1.075      1.947      1.457         32        640: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      1.22G     0.9153      1.245      1.311         23        640: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      1.23G      1.023       1.47      1.386         34        640: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      1.25G     0.9758      1.044      1.337         34        640: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      1.26G     0.5493     0.8292     0.9508         29        640: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      1.28G     0.7212     0.7923      1.174         25        640: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      1.29G     0.7664      1.003      1.164         19        640: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      1.31G     0.7671      1.106      1.122         29        640: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      1.32G      0.896       1.09      1.177         34        640: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      1.34G      1.001     0.9861      1.479         20        640: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      1.35G     0.6848     0.9406      1.084         23        640: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      1.37G     0.6584      1.435       1.09         40        640: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      1.38G     0.8697      1.017      1.258         23        640: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100       1.4G     0.8764     0.7681      1.263         14        640: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      1.41G     0.7879      1.029      1.148         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      1.43G     0.9999      1.108      1.374         17        640: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      1.44G     0.6589     0.8777      1.103         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      1.46G     0.7199     0.9254      1.211         35        640: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      1.47G     0.8262      1.654       1.19         55        640: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100       1.5G     0.6383      1.049       1.08         14        640: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      1.51G     0.7169     0.9855      1.103         46        640: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      1.51G     0.6532      1.136      1.145         30        640: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      1.54G     0.6833      0.849      1.217         22        640: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      1.55G     0.7164     0.7322      1.212         28        640: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      1.56G     0.7792      1.026      1.192         11        640: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      1.59G     0.7671     0.7373      1.254         16        640: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100       1.6G     0.7434      1.025      1.287         30        640: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100       1.6G     0.6051      0.688      1.063         26        640: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      1.63G     0.7546     0.9266      1.297         20        640: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      1.64G     0.6662     0.8457      1.163         16        640: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      1.65G     0.7963     0.7768      1.086         26        640: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      1.67G     0.6187      0.695      1.042         37        640: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      1.69G     0.9413      1.951      1.333         51        640: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      1.69G     0.7584     0.9315      1.182         37        640: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      1.72G     0.6322     0.7745      1.027         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      1.73G     0.7433     0.7106       1.29         12        640: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      1.74G      1.022      1.079      1.452          9        640: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      1.76G     0.6662      0.703      1.152         23        640: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      1.78G     0.6165     0.9729      1.152         21        640: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      1.78G     0.5635     0.5976      1.116         15        640: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      1.81G      1.061       1.89      1.486         28        640: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      1.82G     0.9339     0.8899      1.234         60        640: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      1.83G     0.9155     0.8915      1.335         14        640: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      1.85G     0.6779     0.6292      1.043         37        640: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      1.87G     0.6606      1.006      1.126         45        640: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      1.88G     0.8996      1.456      1.344         16        640: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100       1.9G      0.621     0.6226       1.12         21        640: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      1.91G     0.7918     0.7814      1.107         42        640: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      1.92G     0.4436     0.4465     0.9404         32        640: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      1.94G     0.6752     0.7486      1.039         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 26.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      1.96G     0.8206      1.379      1.272         30        640: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      1.96G     0.6159     0.7253      1.174         26        640: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      1.99G     0.6397     0.8651      1.157         24        640: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100         2G     0.5913     0.6655      1.095         31        640: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      2.02G     0.7254     0.9907      1.119         47        640: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      2.02G     0.6493     0.7954      1.159         26        640: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      2.04G     0.8045     0.6919      1.105         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      2.06G      0.571     0.5492       1.06         13        640: 100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      2.08G     0.4512     0.4808     0.8512         13        640: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      2.08G     0.4633     0.4968     0.9587         13        640: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      2.11G      0.609     0.6229      1.094         13        640: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      2.12G     0.5564     0.6846      1.062         13        640: 100%|██████████| 1/1 [00:00<00:00, 12.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      2.14G     0.8399     0.7876      1.226         13        640: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      2.14G      0.521      0.455     0.8951         13        640: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      2.17G     0.5424     0.6244      1.008         13        640: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      2.18G     0.5596     0.5313      1.007         13        640: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100       2.2G     0.4525       0.45     0.9363         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.852      0.463      0.525      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.015 hours.\n",
      "Optimizer stripped from C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.635      0.783       0.91      0.647\n",
      "                person          3         10      0.616        0.7      0.654      0.325\n",
      "                   dog          1          1      0.517          1      0.995      0.796\n",
      "                 horse          1          2      0.578          1      0.995       0.65\n",
      "              elephant          1          2       0.55          1      0.828      0.323\n",
      "              umbrella          1          1      0.552          1      0.995      0.895\n",
      "          potted plant          1          1          1          0      0.995      0.895\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Source\\iot_dataanalysis_2025\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_results = model.train(\n",
    "    data ='./coco8.yaml' ,\n",
    "    epochs = 100,\n",
    "    imgsz =640,\n",
    "    device = 'cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이미지 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Source\\iot_dataanalysis_2025\\day53\\cat.jpg: 480x640 1 cat, 43.9ms\n",
      "Speed: 7.2ms preprocess, 43.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# yolo11n.pt  모델로 이미지 예측\n",
    "result = model('./cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplot 모듈 로드\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측결과를 이미지+박스로 이미지 만들어 저장하기\n",
    "\n",
    "# 모델이 예측한 객체(바운딩 박스 등)를 이미지 위에 그려준 결과를 NumPy 배열로 얻을 수 있어\n",
    "img = result[0].plot()\n",
    "\n",
    "\n",
    "# img는 OpenCV 스타일의 BGR 포맷이야 (Blue-Green-Red)\n",
    "# PIL.Image.fromarray()는 RGB 포맷을 기대해\n",
    "# 그래서 [..., ::-1]로 채널 순서를 뒤집어서 RGB로 바꾸는 것이야\n",
    "img_pil = Image.fromarray(img[...,::-1])\n",
    "\n",
    "\n",
    "img_pil.save('./predict_result.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OpenCV\n",
    "- Opensource Computer Vision의 약자 . 실시간 컴퓨터비전(시각처리) 목적의 프로그래밍 라이브러리\n",
    "- 인텔에서 2000년에 C, C++ 사용하기 위해서 개발\n",
    "- 파이썬에서 사용할 수 있게 래핑\n",
    "```shell\n",
    ">pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 640, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('./predict_result.jpg')\n",
    "img2.shape     #(464, 640, 3) ->(height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우 창 오픈\n",
    "\n",
    "cv2.imshow('predict_result', img2)\n",
    "\n",
    "# 키보드 입력을 기다리는 함수\n",
    "# 0이면 → 무한히 기다림 (키보드 아무 키나 누를 때까지)\n",
    "# cv2.waitKey(1000)처럼 쓰면 → 1000ms(1초) 동안 기다린 뒤 자동 종료\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# mshow()로 띄운 모든 창을 닫음\n",
    "# 여러 이미지 창을 띄웠을 때도 전부 한 번에 닫아줘요\n",
    "# 안 쓰면 창이 그대로 남아 있을 수 있어요 (특히 Jupyter나 IDE에서는)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './cv2로윈도우창에predict_result띄우기.png' width=500>\n",
    "<img src = './predict_result이미지크기(높이,너비).png' width=500>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 1 bottle, 1 cup, 1 bowl, 1 dining table, 1 tv, 1 mouse, 1 book, 45.9ms\n",
      "Speed: 10.5ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "#objects.jpg 이미지가 너무 커서 사이즈 조정 먼저\n",
    "img = cv2.imread('./objects.jpg')\n",
    "resized_img = cv2.resize(img, (640,400))\n",
    "\n",
    "\n",
    "result = model(resized_img)\n",
    "plots = result[0].plot()\n",
    "\n",
    "cv2.imshow('predct_result2', plots)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './predict_result2를window창에띄우기.png' width=500>\n",
    "<img src = './predict_result2이미지크기.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 동영상 플레이\n",
    "- 라즈베리 웹캠 사용추천\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './sample01.mp4'\n",
    "output_path = './sample01_output.mp4'\n",
    "count_path = './sample01_count.mp4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV 라이브러리를 사용해서 동영상을 재생하는 기본적인 코드\n",
    "\n",
    "#cv2.VideoCapture는 비디오 캡처 객체를 만들어주고, 이 객체를 통해 프레임(이미지) 단위로 동영상을 읽을 수 있어요.\n",
    "cap = cv2.VideoCapture(video_path)  \n",
    "\n",
    "while cap.isOpened():   # 동영상 파일이 정상적으로 열렸는지 확인\n",
    "    ret, frame = cap.read()   # 한 프레임씩 읽습니다. ret은 읽기에 성공했는지를 나타내는 불리언 값 (True 또는 False) frame은 읽어온 실제 **이미지 데이터(프레임)**입니다.\n",
    "    if not ret : break\n",
    "\n",
    "    cv2.imshow('Video Play', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "        break\n",
    "cap.release()  #비디오 캡처 객체를 해제합니다. (메모리 정리)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO 실시간 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시간 모듈 로드\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 1 clock, 22.4ms\n",
      "Speed: 3.2ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 44.3ms\n",
      "Speed: 2.2ms preprocess, 44.3ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 49.9ms\n",
      "Speed: 3.1ms preprocess, 49.9ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 3.6ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.2ms\n",
      "Speed: 1.2ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 1 clock, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.6ms\n",
      "Speed: 1.2ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 toilet, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 4.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 3.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 truck, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 13.2ms\n",
      "Speed: 1.7ms preprocess, 13.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 1 clock, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 6.5ms\n",
      "Speed: 2.5ms preprocess, 6.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.2ms\n",
      "Speed: 2.4ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 7.3ms\n",
      "Speed: 2.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 clock, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 1 clock, 6.8ms\n",
      "Speed: 2.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 train, 1 clock, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 1 clock, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 clock, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.9ms\n",
      "Speed: 2.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 2.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 7.0ms\n",
      "Speed: 2.2ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 2.6ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.8ms\n",
      "Speed: 3.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 truck, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 cell phone, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 suitcase, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 7.0ms\n",
      "Speed: 2.9ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 6.9ms\n",
      "Speed: 2.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 clock, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 clock, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2. VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_time = 1.0/fps\n",
    "\n",
    "# 영상의 프레임 너비와 높이를 가져옴 → 저장할 영상의 사이즈로 사용됨.\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#  영상 저장 객체 설정 (VideoWriter)\n",
    "# fourcc: 동영상 코덱 설정 (여기선 'mp4v' → mp4 파일로 저장 가능)\n",
    "# out: 탐지 결과를 저장할 비디오 파일 생성 (output_path에 저장됨)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : break\n",
    "\n",
    "    # 객체 탐지\n",
    "    results = model(frame)\n",
    "    for result in results :\n",
    "        detect_frame = result.plot()\n",
    "\n",
    "    # 탐지 결과가 표시된 프레임을 새 영상 파일로 저장\n",
    "    out.write(detect_frame)\n",
    "\n",
    "    # detect_frame: 탐지 결과 표시된 영상\n",
    "    cv2.imshow('YOLO Object Detection', detect_frame)\n",
    "    # frame: 원본 영상 (비교용)\n",
    "    cv2.imshow('Video Play', frame)\n",
    "\n",
    "    # 프레임 속도 맞추기\n",
    "    # 실제 처리에 걸린 시간 측정\n",
    "    elapsed_time =time.time() -start_time  \n",
    "    # 영상 원래 속도와 맞추기 위해 delay 계산 (ms 단위)  + 너무 빠르면 최소 1ms 대기\n",
    "    delay = max(int((frame_time-elapsed_time)*1000),1)\n",
    "   \n",
    "    # 종료 조건\n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q') :\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Car counting\n",
    "- 지정된 라인 아래로 내려오는 자동차 개수 카운팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely==2.0.1\n",
      "  Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from shapely==2.0.1) (1.26.4)\n",
      "Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# shapely 설치\n",
    "!pip install shapely==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lap\n",
      "  Downloading lap-0.5.12-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\source\\iot_dataanalysis_2025\\mlvenv\\lib\\site-packages (from lap) (1.26.4)\n",
      "Downloading lap-0.5.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.5 MB 991.0 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.3/1.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#lap 설치치\n",
    "!pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'records': 5, 'show': True, 'model': 'yolo11n.pt', 'line_width': 3}\n",
      "\n",
      "0: 384x640 1 train, 15.8ms\n",
      "Speed: 3.4ms preprocess, 15.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 25.2ms\n",
      "Speed: 5.7ms preprocess, 25.2ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 2 trains, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 toilet, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 2 trains, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 1 truck, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.0ms\n",
      "Speed: 1.1ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 13.8ms\n",
      "Speed: 1.2ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 8 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 9 cars, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.0ms\n",
      "Speed: 3.4ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.2ms\n",
      "Speed: 1.2ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.5ms\n",
      "Speed: 1.1ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'toilet': {'IN': 0, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'traffic light': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) #동영상 FPS\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "line_points = [(20,400),(1080,400)]\n",
    "\n",
    "#videowriter 객체 생성( 동영상 화면에 그림, 글자를 그리기 위한 객체)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(count_path, fourcc, fps, (width, height))\n",
    "\n",
    "#물체 카운터 초기화\n",
    "counter = solutions.ObjectCounter(\n",
    "    show = True ,# 처리하는 동안 디스플레이 여부\n",
    "    region = line_points,\n",
    "    model = 'yolo11n.pt'    #상대 경로 (현재 디렉토리)  . 내부적으로 ./yolo11n.pt로 해석함\n",
    "\n",
    ")\n",
    "\n",
    "# 만약 코드 실행 중에 작업 디렉토리 (cwd)가 바뀌거나,\n",
    "# 혹은 경로가 복잡한 위치에 있을 경우:\n",
    "# 'yolo11n.pt'는 못 찾을 수 있음\n",
    "# './yolo11n.pt' 또는 os.path.abspath()로 명확하게 써야 오류를 피할 수 있음\n",
    "# import os\n",
    "# model_path = os.path.abspath('yolo11n.pt')\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret : break      #자동으로 창이 닫히게\n",
    "\n",
    "    #카운팅 결과를 원본에 바로 그림\n",
    "    results = counter(frame) \n",
    "    out.write(results.plot_im)\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
