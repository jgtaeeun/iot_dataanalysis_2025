{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 \n",
    "### 심층신경망\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모듈 로드\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target) , (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미 mldl01 주피터노트북에서 다운로드 했기에 다시 다운로드 하지 않음\n",
    "- 데이터 위치 C:\\Users\\Admin\\.keras\\datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(-1, 28*28)\n",
    "test_input = test_input.reshape(-1, 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케이링\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_input.astype(np.float64))\n",
    "test_scaled = scaler.transform(test_input.astype(np.float64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트, 검증세트 분리\n",
    "\n",
    "train_scaled, val_scaled, train_target,  val_target = train_test_split(\n",
    "    train_scaled , train_target, random_state=42, test_size=0.2\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (12000, 784) (10000, 784)\n",
      "(48000,) (12000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled.shape,val_scaled.shape, test_scaled.shape)\n",
    "print(train_target.shape,val_target.shape, test_target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 심층신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense = keras.layers.Dense(100, activation='sigmoid', input_shape = (784,))\n",
    "dense2 = keras.layers.Dense(10, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dense\n",
    "    - 입력층 다음의 첫 번째 은닉층(hidden layer)을 정의하는 코드\n",
    "    - 100: 이 층의 뉴런 개수입니다. 이 층에는 100개의 뉴런이 있습니다.\n",
    "    - activation='sigmoid': 각 뉴런의 활성화 함수로 sigmoid를 사용합니다. 이는 입력값을 0과 1 사이의 값으로 변환합니다.\n",
    "    - input_shape=(724,): 입력 데이터의 **형태(shape)**를 지정해줍니다. 즉, 입력으로 들어오는 데이터가 724차원이라는 뜻입니다.\n",
    "\n",
    "- dense2\n",
    "    - 출력층(output layer)**을 정의하는 코드\n",
    "    - 10: 이 층의 뉴런 수는 10개입니다. 보통 **10개의 클래스(분류 대상)**가 있다는 뜻입니다. 예: 숫자 0~9 분류 등\n",
    "    - activation='softmax': softmax는 다중 분류에서 자주 쓰이는 활성화 함수로, 출력값들을 확률처럼 보이게 만들어줍니다. (각 값이 0~1 사이, 전체 합은 1)\n",
    "    - 이 층은 (100차원 입력) → (10차원 출력)으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 생성\n",
    "model = keras.Sequential([dense, dense2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 심층신경망 만들기2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,) , name = 'hidden' ),\n",
    "    keras.layers.Dense(10, activation='softmax',  name = 'output' )\n",
    "] , name = 'Fashio_MNIST_Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashio_MNIST_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 2s 844us/step - loss: 0.4688 - accuracy: 0.8365\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 1s 928us/step - loss: 0.3559 - accuracy: 0.8722\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 1s 902us/step - loss: 0.3192 - accuracy: 0.8845\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 1s 889us/step - loss: 0.2941 - accuracy: 0.8956\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 1s 848us/step - loss: 0.2748 - accuracy: 0.9006\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.2583 - accuracy: 0.9069\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.2436 - accuracy: 0.9119\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 1s 878us/step - loss: 0.2302 - accuracy: 0.9171\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 0.2192 - accuracy: 0.9217\n",
      "Epoch 10/100\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.2092 - accuracy: 0.9250\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.1988 - accuracy: 0.9309\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 1s 862us/step - loss: 0.1887 - accuracy: 0.9348\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.1802 - accuracy: 0.9361\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 1s 915us/step - loss: 0.1711 - accuracy: 0.9403\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 1s 913us/step - loss: 0.1637 - accuracy: 0.9442\n",
      "Epoch 16/100\n",
      "  54/1500 [>.............................] - ETA: 1s - loss: 0.1350 - accuracy: 0.9589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#훈련\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1813\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[39m\n\u001b[32m   1811\u001b[39m logs = tmp_logs\n\u001b[32m   1812\u001b[39m end_step = step + data_handler.step_increment\n\u001b[32m-> \u001b[39m\u001b[32m1813\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n\u001b[32m   1815\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:475\u001b[39m, in \u001b[36mCallbackList.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[32m    469\u001b[39m \n\u001b[32m    470\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[33;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[32m    473\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_call_train_batch_hooks:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:322\u001b[39m, in \u001b[36mCallbackList._call_batch_hook\u001b[39m\u001b[34m(self, mode, hook, batch, logs)\u001b[39m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_batch_begin_hook(mode, batch, logs)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m hook == \u001b[33m\"\u001b[39m\u001b[33mend\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    325\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    326\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mExpected values are [\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbegin\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mend\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    327\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:345\u001b[39m, in \u001b[36mCallbackList._call_batch_end_hook\u001b[39m\u001b[34m(self, mode, batch, logs)\u001b[39m\n\u001b[32m    342\u001b[39m     batch_time = time.time() - \u001b[38;5;28mself\u001b[39m._batch_start_time\n\u001b[32m    343\u001b[39m     \u001b[38;5;28mself\u001b[39m._batch_times.append(batch_time)\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._batch_times) >= \u001b[38;5;28mself\u001b[39m._num_batches_for_timing_check:\n\u001b[32m    348\u001b[39m     end_hook_name = hook_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:393\u001b[39m, in \u001b[36mCallbackList._call_batch_hook_helper\u001b[39m\u001b[34m(self, hook_name, batch, logs)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m    392\u001b[39m     hook = \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_timing:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hook_times:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:1093\u001b[39m, in \u001b[36mProgbarLogger.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\callbacks.py:1170\u001b[39m, in \u001b[36mProgbarLogger._batch_update_progbar\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m   1168\u001b[39m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[32m   1169\u001b[39m     logs = tf_utils.sync_to_numpy_or_python_type(logs)\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\utils\\generic_utils.py:296\u001b[39m, in \u001b[36mProgbar.update\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    293\u001b[39m         info += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m     message += info\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[43mio_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m     message = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\utils\\io_utils.py:80\u001b[39m, in \u001b[36mprint_msg\u001b[39m\u001b[34m(message, line_break)\u001b[39m\n\u001b[32m     78\u001b[39m         sys.stdout.write(message + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     sys.stdout.flush()\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3027\u001b[39m, in \u001b[36mInteractiveShell._tee.<locals>.write\u001b[39m\u001b[34m(data, *args, **kwargs)\u001b[39m\n\u001b[32m   3025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(data, *args, **kwargs):\n\u001b[32m   3026\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data to both the original destination and the capture dictionary.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3027\u001b[39m     result = \u001b[43moriginal_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3028\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   3029\u001b[39m         [\n\u001b[32m   3030\u001b[39m             \u001b[38;5;28mself\u001b[39m.display_pub.is_publishing,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3033\u001b[39m         ]\n\u001b[32m   3034\u001b[39m     ):\n\u001b[32m   3035\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\ipykernel\\iostream.py:694\u001b[39m, in \u001b[36mOutStream.write\u001b[39m\u001b[34m(self, string)\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(\u001b[38;5;28mself\u001b[39m._flush)\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\ipykernel\\iostream.py:590\u001b[39m, in \u001b[36mOutStream._schedule_flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_schedule_in_thread\u001b[39m():\n\u001b[32m    588\u001b[39m     \u001b[38;5;28mself\u001b[39m._io_loop.call_later(\u001b[38;5;28mself\u001b[39m.flush_interval, \u001b[38;5;28mself\u001b[39m._flush)\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpub_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[39m, in \u001b[36mIOPubThread.schedule\u001b[39m\u001b[34m(self, f)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m._events.append(f)\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event_pipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     f()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\zmq\\sugar\\socket.py:698\u001b[39m, in \u001b[36mSocket.send\u001b[39m\u001b[34m(self, data, flags, copy, track, routing_id, group)\u001b[39m\n\u001b[32m    691\u001b[39m         data = zmq.Frame(\n\u001b[32m    692\u001b[39m             data,\n\u001b[32m    693\u001b[39m             track=track,\n\u001b[32m    694\u001b[39m             copy=copy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    695\u001b[39m             copy_threshold=\u001b[38;5;28mself\u001b[39m.copy_threshold,\n\u001b[32m    696\u001b[39m         )\n\u001b[32m    697\u001b[39m     data.group = group\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1081\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1129\u001b[39m, in \u001b[36mzmq.backend.cython._zmq.Socket.send\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:1397\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._send_copy\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_zmq.py:169\u001b[39m, in \u001b[36mzmq.backend.cython._zmq._check_rc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#훈련\n",
    "model.fit(train_scaled,  train_target, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 726us/step - loss: 0.8698 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8698276281356812, 0.8740000128746033]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled,val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 665us/step\n"
     ]
    }
   ],
   "source": [
    "pred_result = model.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, font_manager, rc\n",
    "\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # 나눔고딕코딩 사용, 나눔고딕에서 오류발생(!)\n",
    "font = font_manager.FontProperties(fname=font_path).get_name() # 실제 설치된 폰트 이름조회\n",
    "rc('font', family=font) # 한글깨짐현상 해결!!\n",
    "rcParams['axes.unicode_minus'] = False # 한글 사용시 마이너스 표시 깨짐 해결!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['티셔츠','바지','스웨터','드레스','코트','샌들','셔츠','스니커즈','가방','앵클부츠']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트이미지와 예측결과 시각화\n",
    "\n",
    "#pred_result[index]: 모델이 예측한 확률 벡터입니다 (예: [0.01, 0.03, ..., 0.9]).\n",
    "#np.argmax(...): 확률이 가장 높은 인덱스를 구합니다 → 예측된 클래스.\n",
    "\n",
    "\n",
    "def show_image(index):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(test_input[index].reshape(28, 28), cmap='gray_r')\n",
    "    true_label = class_names[test_target[index]]\n",
    "    pred_label = class_names[np.argmax(pred_result[index])]\n",
    "    plt.text(0,-6,f'실제 : {true_label}', fontsize= 12, color = 'red')\n",
    "    plt.text(0,-3,f'예측 : {pred_label}', fontsize= 12, color = 'blue')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(11,17):\n",
    "    show_image(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLu 함수\n",
    "- 인공신경망 은닉층에 초기에는 Sigmoid함수 사용\n",
    "    - 단점 : 오른쪽, 왼쪽 끝으로 갈수록 그래프가 누워 있어서 올바른 출력을 못 만든다.\n",
    "\n",
    "- 렐루함수(ReLu) : 수정된 선형 유닛 뜻의 함수\n",
    "    - <img src = './렐루함수.png' width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten 객체\n",
    "- 이미지 2차원배열을 1차원으로 변경할 때, np.reshape() 사용\n",
    "- Flatten 클래스가 위의 일을 대신해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28), name= 'Flatten'),\n",
    "    keras.layers.Dense(100, activation='relu',  name = 'hidden' ),\n",
    "    keras.layers.Dense(10, activation='softmax',  name = 'output' ),\n",
    "] , name = 'Fashio_MNIST_Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashio_MNIST_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_input, train_target] , [test_input, test_target] = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "# 이미지 데이터는 보통 픽셀 값이 0~255 사이의 정수로 되어 있음.\n",
    "#255.0으로 나누면 모든 값이 0~1 사이의 실수 값으로 바뀜.\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "test_scaled = test_input / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "\n",
    "    train_scaled, train_target, random_state=42 , test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 899us/step - loss: 0.5395 - accuracy: 0.8114\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 1s 920us/step - loss: 0.3951 - accuracy: 0.8574\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 923us/step - loss: 0.3574 - accuracy: 0.8704\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 890us/step - loss: 0.3350 - accuracy: 0.8799\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 904us/step - loss: 0.3187 - accuracy: 0.8854\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 0.3059 - accuracy: 0.8914\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 1s 915us/step - loss: 0.2982 - accuracy: 0.8941\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 956us/step - loss: 0.2873 - accuracy: 0.8981\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 942us/step - loss: 0.2800 - accuracy: 0.9005\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 1s 951us/step - loss: 0.2745 - accuracy: 0.9031\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 1s 935us/step - loss: 0.2707 - accuracy: 0.9057\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 917us/step - loss: 0.2610 - accuracy: 0.9067\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 926us/step - loss: 0.2564 - accuracy: 0.9099\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 0.2534 - accuracy: 0.9113\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 919us/step - loss: 0.2484 - accuracy: 0.9134\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 909us/step - loss: 0.2401 - accuracy: 0.9161\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 882us/step - loss: 0.2378 - accuracy: 0.9171\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 871us/step - loss: 0.2331 - accuracy: 0.9182\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 876us/step - loss: 0.2306 - accuracy: 0.9201\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.2274 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc0df8bf50>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_scaled, train_target, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 694us/step - loss: 0.4392 - accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4392000436782837, 0.8812500238418579]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시그모이드 활성화함수 사용했을 때  [0.8626047968864441, 0.8789166808128357]\n",
    "- 렐루 활성화함수 사용했을 때   [0.42934268712997437, 0.8820000290870667]\n",
    "- 렐루 함수가 정확도 0.01% 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 옵티마이저\n",
    "- 하이퍼 파라미터 값 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28), name= 'Flatten'),\n",
    "    keras.layers.Dense(100, activation='relu',  name = 'hidden' ),\n",
    "    keras.layers.Dense(10, activation='softmax',  name = 'output' ),\n",
    "] , name = 'Fashio_MNIST_Model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델3 설정, 최적화는 adam클래스만 사용할 것\n",
    "model3.compile(loss='sparse_categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 922us/step - loss: 0.5250 - accuracy: 0.8184\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 1s 958us/step - loss: 0.3968 - accuracy: 0.8583\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 941us/step - loss: 0.3532 - accuracy: 0.8732\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 0.3289 - accuracy: 0.8804\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 917us/step - loss: 0.3098 - accuracy: 0.8873\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 1s 930us/step - loss: 0.2910 - accuracy: 0.8929\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 1s 964us/step - loss: 0.2795 - accuracy: 0.8970\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 0.2676 - accuracy: 0.9005\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 965us/step - loss: 0.2583 - accuracy: 0.9049\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 1s 996us/step - loss: 0.2485 - accuracy: 0.9075\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 1s 969us/step - loss: 0.2434 - accuracy: 0.9089\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 950us/step - loss: 0.2319 - accuracy: 0.9152\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 912us/step - loss: 0.2263 - accuracy: 0.9161\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 908us/step - loss: 0.2197 - accuracy: 0.9181\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 963us/step - loss: 0.2114 - accuracy: 0.9214\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 958us/step - loss: 0.2074 - accuracy: 0.9223\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 952us/step - loss: 0.1996 - accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 935us/step - loss: 0.1952 - accuracy: 0.9271\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 960us/step - loss: 0.1911 - accuracy: 0.9292\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 964us/step - loss: 0.1875 - accuracy: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc0cfcc690>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_scaled, train_target, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 1s 971us/step - loss: 0.1813 - accuracy: 0.9319\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1771 - accuracy: 0.9348\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 999us/step - loss: 0.1728 - accuracy: 0.9357\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 971us/step - loss: 0.1687 - accuracy: 0.9360\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 996us/step - loss: 0.1645 - accuracy: 0.9385\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1610 - accuracy: 0.9396\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1564 - accuracy: 0.9418\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 964us/step - loss: 0.1532 - accuracy: 0.9431\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 936us/step - loss: 0.1499 - accuracy: 0.9447\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 1s 966us/step - loss: 0.1475 - accuracy: 0.9457\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 1s 999us/step - loss: 0.1448 - accuracy: 0.9456\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 945us/step - loss: 0.1409 - accuracy: 0.9481\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 957us/step - loss: 0.1382 - accuracy: 0.9477\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 939us/step - loss: 0.1347 - accuracy: 0.9492\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 982us/step - loss: 0.1317 - accuracy: 0.9516\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 976us/step - loss: 0.1291 - accuracy: 0.9513\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 955us/step - loss: 0.1281 - accuracy: 0.9525\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 926us/step - loss: 0.1236 - accuracy: 0.9537\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 927us/step - loss: 0.1210 - accuracy: 0.9554\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 0.1209 - accuracy: 0.9541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc0d0a9610>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델훈련은 정보를 저장하기 때문에 다시 수행하면 이전 정보를 담고 시작\n",
    "# 이전의 fit 정확도 0.9305를 이어서 실행함\n",
    "# 즉 epochs =40을 실행한 것임\n",
    "model3.fit(train_scaled, train_target, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer 사용시, 정확도 0.01% 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 693us/step - loss: 0.4290 - accuracy: 0.8892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4289517402648926, 0.8891666531562805]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 드롭아웃\n",
    "- 훈련과정 밀집층에 일부 뉴런을 꺼버림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28), name= 'Flatten'),\n",
    "    keras.layers.Dense(100, activation='relu',  name = 'hidden' ),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation='softmax',  name = 'output' ),\n",
    "] , name = 'Fashio_MNIST_ReLu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashio_MNIST_ReLu\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='sparse_categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3123 - accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3043 - accuracy: 0.8879\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3034 - accuracy: 0.8856\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2985 - accuracy: 0.8885\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2941 - accuracy: 0.8905\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2880 - accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2839 - accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2838 - accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2788 - accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2734 - accuracy: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc12159610>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs 10을 두번 실행해서\n",
    "# 결국 epochs 20을 실행한 결과\n",
    "model4.fit(train_scaled,train_target,epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 709us/step - loss: 0.3204 - accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3204251229763031, 0.8872500061988831]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 드롭아웃 넣은 모델 model4 실행 결과 [0.3204251229763031, 0.8872500061988831]\n",
    "- 드롭아웃 없는 모델 model3 실행결과 [0.4289517402648926, 0.8891666531562805]\n",
    "- 드롭아웃하면 정확도 떨어짐 > 훈련과 검증(테스트) 사이에 정확도 차이가 줄어듬\n",
    "- 과대적합(훈련세트훈련에 너무 치중하여서 정확도가 너무 높은 것 )방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델의 저장과 복원\n",
    "- 훈련시간이 딥러닝에 크게 좌우됨. 저장이 없으면 다시 훈련시키고 시간을 소요해야 됨\n",
    "- 파일로 저장후 모델에 대한 구조와 파라미터만 저장하는 두가지 방법이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 4 저장 - 파라미터만 저장\n",
    "model4.save_weights('./model4-weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델 4 저장 - 전체(모델 구조와 파라미터) 저장\n",
    "model4.save('./model4-whole.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 사용\n",
    "- 파라미터만 지정한 파일을 사용하려면, 먼저 모델을 생성해야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.load_weights('./model4-weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 646us/step\n"
     ]
    }
   ],
   "source": [
    "pred_result = model5.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델까지 전부 생성해주는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = keras.models.load_model('./model4-whole.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashio_MNIST_ReLu\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 726us/step - loss: 0.3204 - accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3204251229763031, 0.8872500061988831]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 콜백\n",
    "- 실행도중 다른 일을 할 수 있도록 해주는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28), name= 'Flatten'),\n",
    "    keras.layers.Dense(100, activation='relu',  name = 'hidden' ),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(10, activation='softmax',  name = 'output' ),\n",
    "] , name = 'Fashio_MNIST_ReLu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.compile(loss='sparse_categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크마다 모델 저장 기능\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('./best-model.h5', save_best_only=True)    #최고 상태일 때 저장\n",
    "# 조기종료\n",
    "# 두번이상 훈련값이 동일하면 조기종료, 이전 최고상태로 복구\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5909 - accuracy: 0.7937 - val_loss: 0.4513 - val_accuracy: 0.8298\n",
      "Epoch 2/20\n",
      " 158/1500 [==>...........................] - ETA: 1s - loss: 0.4475 - accuracy: 0.8441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Source\\iot_dataanalysis_2025\\mlvenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4393 - accuracy: 0.8405 - val_loss: 0.3883 - val_accuracy: 0.8592\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4033 - accuracy: 0.8531 - val_loss: 0.3636 - val_accuracy: 0.8668\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3831 - accuracy: 0.8609 - val_loss: 0.3558 - val_accuracy: 0.8717\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3677 - accuracy: 0.8660 - val_loss: 0.3431 - val_accuracy: 0.8736\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3536 - accuracy: 0.8691 - val_loss: 0.3341 - val_accuracy: 0.8786\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3426 - accuracy: 0.8730 - val_loss: 0.3373 - val_accuracy: 0.8769\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3351 - accuracy: 0.8778 - val_loss: 0.3374 - val_accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1db78f64750>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model7.fit(train_scaled,train_target,epochs=20, validation_data=(val_scaled, val_target),\n",
    "           callbacks=[checkpoint_cb, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb.stopped_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- patience=2이고, 에포크 6에서 최고 성능이었다면,\n",
    "- 에포크 7,8에서 개선이 없으면,\n",
    "- 에포크 8이 끝난 직후, “이제 멈춰야겠다”라고 결정합니다.\n",
    "- 그래서 8까지 출력은 되지만, stopped_epoch=7가 되는 거예요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결론\n",
    "- `심층신경망`: 2개이상의 밀집층을 포함한 신경망 모델. 다층 인공신경망\n",
    "- `렐루함수` : 시그모이드 함수의 단점을 보완한 활성화 함수\n",
    "- `옵티마이저` : 신경망의 가중치(기울기)와 절편을 학습하기 위한 알고리즘 또는 방법. Adam,  SGD(확률적 경사 하강법)...\n",
    "\n",
    "- `드롭아웃` : 밀집층의 뉴런을 임의로 꺼서 훈련을 덜 시키는 것. 과대적합 막기 위해서 수행\n",
    "- 모델 저장과 복원: 이미 훈련된 데이터를 저장했다가 나중에 다시 쓰기 위해서\n",
    "- 콜백 - 에포크마다 모델 저장 또는 조기종료를 위해서 훈련 도중에 다른 기능을 수행하는 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
