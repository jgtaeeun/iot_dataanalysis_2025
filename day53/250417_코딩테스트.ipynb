{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0299583e",
   "metadata": {
    "id": "0299583e"
   },
   "source": [
    "## 코딩테스트\n",
    "\n",
    "### MNIST 손글씨 숫자 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8faf2380",
   "metadata": {
    "id": "8faf2380"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba33f2c",
   "metadata": {
    "id": "6ba33f2c"
   },
   "source": [
    "### 데이터 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5763f27a",
   "metadata": {
    "id": "5763f27a",
    "outputId": "d0012b07-9c76-4f03-d7c7-77960d527ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU/GPU: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:06<00:00, 1.60MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 156kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.43MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.27MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'CPU/GPU: {device}')\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd9934",
   "metadata": {},
   "source": [
    "<img src ='./코딩테스트_데이터준비.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f98a6f",
   "metadata": {
    "id": "79f98a6f"
   },
   "source": [
    "### CNN 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850f093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 총 개수: 60000\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터셋의 기본 구성\n",
    "# 학습 데이터 (train_set): 60,000개\n",
    "# 테스트 데이터 (test_set): 10,000개\n",
    "\n",
    "print(f\"학습 데이터의 총 개수: {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee791aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 shape: torch.Size([1, 28, 28])\n",
      "라벨: 5\n"
     ]
    }
   ],
   "source": [
    "image, label = train_set[0]\n",
    "\n",
    "# 이미지 shape 확인\n",
    "print(f\"이미지 shape: {image.shape}\")  # torch.Size([1, 28, 28])\n",
    "print(f\"라벨: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263c99b0",
   "metadata": {
    "id": "263c99b0"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)   #[1,28,28] ->[16,26,26] 커널사이즈 3*3 , 스트라이드 기본값 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)                  # 맥스풀링하면 절반됨 [16,26,26] ->[16,13,13]\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)   #[16,13,13] ->[32,11,11] 커널사이즈 3*3 , 스트라이드 기본값 1\n",
    "                                                        # 맥스풀링하면 절반됨 [32,11,11] ->[32,5,5]  \n",
    "                                                        # 마지막 행과 열은 2x2 풀링 윈도우에 들어갈 수 없어서 그냥 버려지는 게 맞습니다.\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)           # 128개의 특징(벡터)으로 압축 /이 128은 하이퍼파라미터예요!\n",
    "        self.fc2 = nn.Linear(128, 10)                   #  128차원의 특징 벡터를 MNIST 숫자 분류 문제(클래스 10개)에 맞게\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 문제. 아래의 주석을 풀고 알맞은 Flatten 내용을 추가하시오.\n",
    "        x = x.view(-1,32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46145b44",
   "metadata": {
    "id": "46145b44"
   },
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f41a8",
   "metadata": {
    "id": "011f41a8"
   },
   "source": [
    "### 손실함수와 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6711155f",
   "metadata": {
    "id": "6711155f"
   },
   "outputs": [],
   "source": [
    "#CrossEntropyLoss는 다중 클래스 분류 문제에서 자주 쓰이는 손실 함수로, 예측값과 실제값 사이의 오차를 측정합니다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# 문제: 아래의 주석을 해제, Adam 옵티마이저를 설정하고 학습률은 0.001로 지정하세요.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e8d7f0",
   "metadata": {
    "id": "42e8d7f0"
   },
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3103fc24",
   "metadata": {
    "id": "3103fc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.2085\n",
      "[Epoch 2] Loss: 0.0636\n",
      "[Epoch 3] Loss: 0.0449\n",
      "[Epoch 4] Loss: 0.0335\n",
      "[Epoch 5] Loss: 0.0266\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        # 문제: 아래의 주석 해제, 손실(loss)를 계산하세요.\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45b032",
   "metadata": {},
   "source": [
    "- 학습 데이터:\n",
    "    - MNIST의 학습 데이터는 60,000개의 이미지입니다.\n",
    "- 배치 크기:\n",
    "    - 배치 크기가 64이므로, 한 번에 64개의 이미지를 처리합니다.\n",
    "- 배치 개수:\n",
    "    - 학습 데이터 60,000개를 배치 크기 64로 나누면, 총 배치 개수는 938개입니다.\n",
    "    - 즉, 한 에폭 동안 모델은 938번의 배치에 대해 학습을 하게 됩니다.\n",
    "- running_loss:\n",
    "    - 각 배치에 대해 손실 값을 계산한 후, 그 손실 값은 running_loss에 누적됩니다.\n",
    "    - 이 손실 값들은 해당 938개의 배치에서 계산된 손실들의 합입니다.\n",
    "- 평균 손실 계산:\n",
    "    - running_loss / len(train_loader)에서 len(train_loader)는 배치 개수, 즉 938입니다.\n",
    "    - running_loss는 938개의 배치에 대한 손실의 합이므로, 이를 938개 배치의 평균 손실로 나누게 되는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f267b62",
   "metadata": {
    "id": "2f267b62"
   },
   "source": [
    "### 평가 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d80a86",
   "metadata": {
    "id": "50d80a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도: 98.77%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)   # 각 배치에서 가장 높은 확률을 가진 클래스를 예측값으로 선택합니다.\n",
    "        total += labels.size(0)                # 전체 테스트 데이터에 대한 정확도를 계산하려면, 전체 데이터 수를 누적해야 합니다.\n",
    "        # 문제: 주석해제 후, 정확히 예측한 개수를 누적하세요.\n",
    "        correct +=  (predicted == labels).sum().item()\n",
    "\n",
    "print(f'테스트 정확도: {100 * correct / total:.2f}%')\n",
    "\n",
    "# 문제: 모델 저장 (선택) - 학습된 모델을 'mnist_cnn.pth' 파일로 저장하는 코드를 작성하시오\n",
    "torch.save(model, 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2f5b9",
   "metadata": {
    "id": "92e2f5b9"
   },
   "source": [
    "#### 위의 내용을 CUDA에서 동작하도록 하나의 셀에 작성 완성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "R6TrLM55Tzc4",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744785345623,
     "user": {
      "displayName": "MG “Hugo” Sung",
      "userId": "01836946422587818310"
     },
     "user_tz": -540
    },
    "id": "R6TrLM55Tzc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU/GPU: cuda\n",
      "[Epoch 1] Loss: 0.2461\n",
      "[Epoch 2] Loss: 0.0662\n",
      "[Epoch 3] Loss: 0.0468\n",
      "[Epoch 4] Loss: 0.0350\n",
      "[Epoch 5] Loss: 0.0299\n",
      "테스트 정확도: 98.95%\n"
     ]
    }
   ],
   "source": [
    "# 문제: 전체 소스 작성\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'CPU/GPU: {device}')\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# 모델\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)   #[1,28,28] ->[16,26,26] 커널사이즈 3*3 , 스트라이드 기본값 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)                  # 맥스풀링하면 절반됨 [16,26,26] ->[16,13,13]\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)   #[16,13,13] ->[32,11,11] 커널사이즈 3*3 , 스트라이드 기본값 1\n",
    "                                                        # 맥스풀링하면 절반됨 [32,11,11] ->[32,5,5]  \n",
    "                                                        # 마지막 행과 열은 2x2 풀링 윈도우에 들어갈 수 없어서 그냥 버려지는 게 맞습니다.\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)           # 128개의 특징(벡터)으로 압축 /이 128은 하이퍼파라미터예요!\n",
    "        self.fc2 = nn.Linear(128, 10)                   #  128차원의 특징 벡터를 MNIST 숫자 분류 문제(클래스 10개)에 맞게\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# 학습\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 검증\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)               \n",
    "        correct +=  (predicted == labels).sum().item()\n",
    "\n",
    "print(f'테스트 정확도: {100 * correct / total:.2f}%')\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model, 'mnist_cnn.pth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
